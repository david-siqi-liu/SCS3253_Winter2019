{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markdown referece can be found here:\n",
    "    http://nestacms.com/docs/creating-content/markdown-cheat-sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Why would it be a problem if our training set and test set are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre> Remember the puporse of machine learning is to be able to generalize with data the algorithm has never seen.\n",
    "\n",
    "If you train and test with the same data, you are evaluating the performance on the same peace of data. Therefore, you would not be able to know whether the algorithm actually would perform on unseen data. </pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. Explain step by step the process to select k in the k-nearest neighbor algorithm (pseudocode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre> The rule of thumb is to start with k as the square root of n (the number of training examples). K should also be odd in most cases to avoid ties. We can then lower k, which will decrease bias but increase variance, or increase k, which would increase bias but decrease variance. We can decide which way to change k depending on the problem we are trying to solve. \n",
    "\n",
    "Read the following discussion for more info (K-Fold Cross Validation)\n",
    "https://www.researchgate.net/post/How_can_we_find_the_optimum_K_in_K-Nearest_Neighbor\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. For the k-nearest regression. What happends when k = n. Where n is equal tot he training size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre> If we set k = n, the prediction will be the same for any new data point -> Average of all poins in the training set. </pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Define a function that takes a 1-d numpy array, a parameter k, and a number p.\n",
    "The function returns an estimate equal to the mean of the closest k points to the number p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def k_neighbor(input_data, k, p):\n",
    "    \"\"\"Returns the k-neighbor estimate for p using data input_data.\n",
    "\n",
    "    Keyword arguments:\n",
    "    input_data -- numpy array of all the data\n",
    "    k -- Number of k\n",
    "    p -- input values\n",
    "    \"\"\"\n",
    "    arr = (((p - input_data)**2))**0.5\n",
    "    ind = np.argpartition(arr, k)[:k]\n",
    "    return(np.mean(input_data[ind]))\n",
    "    #YOUR CODE HERE\n",
    "    \n",
    "    \n",
    "    #return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.33333333333\n",
      "14.0\n",
      "26.0\n",
      "40.0\n",
      "31.3333333333\n",
      "19.6\n"
     ]
    }
   ],
   "source": [
    "#Evaluate\n",
    "data = np.array([1,3,4,5,7,8,11,12,13,15,19,24,25,29,40])\n",
    "print(k_neighbor(input_data=data, k=3, p=5))\n",
    "print(k_neighbor(input_data=data, k=2, p=15))\n",
    "print(k_neighbor(input_data=data, k=3, p=25))\n",
    "print(k_neighbor(input_data=data, k=1, p=55))\n",
    "print(k_neighbor(input_data=data, k=3, p=55))\n",
    "print(k_neighbor(input_data=data, k=10, p=55))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Similar to Q4 but for the n dimentional case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def l1_norm(a,b):\n",
    "    \"\"\"Returns the l1 norm (a,b)\"\"\"\n",
    "    return sum(abs(a - b))\n",
    "    \n",
    "def l2_norm(a,b):\n",
    "    \"\"\"Returns the l2 norm (a,b)\"\"\" \n",
    "    return (sum((b - a)**2))**0.5\n",
    "    \n",
    "def k_neighbor_nd(input_data, k, p, metric='l1', mode='mean'):\n",
    "    \"\"\"Returns the k-neighbor estimate for p using data input_data.\n",
    "\n",
    "    Keyword arguments:\n",
    "    input_data -- numpy array of all the data\n",
    "    k -- Number of k\n",
    "    p -- input values\n",
    "    metric -- l1 or l2. l1 norm or l2 norm https://en.wikipedia.org/wiki/Norm_(mathematics)\n",
    "    mode -- estimator possible values = 'mean', 'median', 'max'\n",
    "    \n",
    "    Implement the l1 and l2 norms\n",
    "    for mean, median and max, use np.mean, np.median and np.max\n",
    "    \"\"\"\n",
    "    \n",
    "    #YOUR CODE HERE\n",
    "    if metric == 'l1':\n",
    "        arr = np.zeros(0)\n",
    "        for i in range(0, input_data.shape[0]):\n",
    "            arr = np.append(arr, l1_norm(p, input_data[i]))\n",
    "            \n",
    "    if metric == 'l2':\n",
    "        arr = np.zeros(0)\n",
    "        for i in range(0, input_data.shape[0]):\n",
    "            arr = np.append(arr, l2_norm(p, input_data[i]))\n",
    "            \n",
    "            \n",
    "    ind = np.argpartition(arr, k)[:k]\n",
    "    \n",
    "    if mode == 'mean':\n",
    "        return(np.mean(input_data[ind], axis = 0))\n",
    "    \n",
    "    if mode == 'median':\n",
    "        return(np.median(input_data[ind], axis = 0))\n",
    "    \n",
    "    if mode == 'max':\n",
    "        return(np.max(input_data[ind], axis = 0))\n",
    "    \n",
    "    #return answer\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_4d = np.array([[4, 1, 2, 1], [1, 4, 2, 0], [3, 3, 1, 1], \n",
    "        [4, 0, 0, 0], [1, 2, 0, 0], [3, 4, 2, 3], \n",
    "        [2, 4, 4, 2], [2, 1, 4, 1], [3, 3, 2, 4], \n",
    "        [4, 3, 0, 4], [2, 2, 4, 0],[4, 3, 0, 2], \n",
    "        [4, 3, 0, 2], [0, 3, 4, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.          2.33333333  4.          1.        ]\n",
      "[ 4.  3.  0.  2.]\n",
      "[4 4 2 4]\n",
      "[ 3.  3.  2.  4.]\n",
      "[ 3.  4.  2.  3.]\n",
      "[ 1.33333333  2.          4.          1.        ]\n",
      "[ 3.5  3.   0.5  1.5]\n",
      "[4 4 2 4]\n",
      "[ 3.  3.  2.  4.]\n",
      "[ 3.  4.  2.  3.]\n"
     ]
    }
   ],
   "source": [
    "#Evaluate\n",
    "data = np.array([1,3,4,5,7,8,11,12,13,15,19,24,25,29,40])\n",
    "print(k_neighbor_nd(input_data=data_4d, k=3, p=[2, 1, 4, 3], metric='l1', mode='mean'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=2, p=[4, 4, 0, 0], metric='l1', mode='mean'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=3, p=[2, 2, 2, 4], metric='l1', mode='max'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=1, p=[2, 3, 3, 4], metric='l1', mode='mean'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=3, p=[2, 3, 3, 4], metric='l1', mode='median'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=3, p=[2, 1, 4, 3], metric='l2', mode='mean'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=2, p=[4, 4, 0, 0], metric='l2', mode='mean'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=3, p=[2, 2, 2, 4], metric='l2', mode='max'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=1, p=[2, 3, 3, 4], metric='l2', mode='mean'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=3, p=[2, 3, 3, 4], metric='l2', mode='median'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. Read the documentation on KNeighborsRegressor\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html\n",
    "    \n",
    "Explore the source code:\n",
    "    https://github.com/scikit-learn/scikit-learn/blob/ef5cb84a/sklearn/neighbors/regression.py\n",
    "        \n",
    "How different it is from your implementation? How well can you follow the code? Did you learn something new?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre> Each person will have a different experience\n",
    "</pre>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
